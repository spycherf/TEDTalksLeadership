{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Impact of Charismatic and Leader-Like Speakers on Their Audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to GitHub](https://github.com/spycherf/TEDTalksLeadership/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the final report of a data mining & machine learning semester project done by Frederic Spycher under the supervision of Prof. Michalis Vlachos (University of Lausanne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a large amount of transcripts from TED and TEDx talks, our project aims at exploring the relationship between the use of **charismatic leadership tactics** (CLTs) and **follower reaction**. CLTs refer to speech techniques such as metaphors, stories, three-part lists, etc. (Antonakis et al., 2012). Follower reaction is an indicator of popularity derived from metrics such as the number of views or YouTube \"(dis)likes\".\n",
    "\n",
    "TED talks represent good research material because, in most cases, they feature speakers trying their best to be inspiring and to convey a message. As such, they are a good place to look for CLTs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project builds on previous work done by Prof. John Antonakis (University of Lausanne) and his colleagues around **leadership** and **charisma** (see Antonakis, 2006; Antonakis et al., 2016 among others).\n",
    "\n",
    "Partnering with Prof. Antonakis, Philip N. Garner and his team from the Idiap Research Institute in Martigny (Switzerland) trained a **recurrent neural network** based on the transcripts of 240 TED talks, to estimate the usage probability of CLTs in textual data (for more details on the model, see Garner et al., 2018). The CLTs in each transcript had to be coded by hand using specific guidelines.\n",
    "\n",
    "This deep learning model allows the **prediction of the nine CLT values** (`collective`, `contrast`, `goal`, `goals2`, `list`, `metaphor`, `moral`, `question`, `story`) for any given text. If CLTs do indeed correlate positively with the aforementioned metrics, then testing this tool on a larger data pool would be a good way of checking its performance. It may very well be that the deep learning tool requires more training data to provide more consistent and accurate results. If anything, the data collected in the scope of our project provide **more observations** to train the model (although the initial coding of CLTs would still have to be done manually).\n",
    "\n",
    "Parting ways with the analysis based on CLTs, our data can also be used with another machine learning application, namely **IBM Watson Personality Insights**, which makes a psycholinguistic analysis of text to predict scores in each of the Big Five personality traits ([OCEAN model](https://en.wikipedia.org/wiki/Big_Five_personality_traits)), as well as some additional metrics such as consumer needs and values. It is meant to be more of a business application, but since personality traits like extroversion and openness to experience are thought to be qualities of a good leader (see works cited by Antonakis, 2006), it constitutes an interesting approach to compare with the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mining efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of this semester project was to collect the data necessary for further machine learning experimentation and analysis. The main goal was to gather **as many English transcripts as possible**.\n",
    "\n",
    "The initial dataset was scraped directly from the **TED website**. In order to get additional metadata (mostly the number of likes and dislikes) as well as additional transcripts, we turned to **YouTube**. The advantage of YouTube is that it also provides autogenerated transcripts of reasonably good quality (as far as English is concerned).\n",
    "\n",
    "The gathered transcripts were then fed to the IBM tool to extract the **personality profiles**.\n",
    "\n",
    "Finally, at the request of Prof. Antonakis, we obtained estimates of the **age and gender** of the speakers. Two different approaches were used based on images and audio files, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the data output by the Idiap and IBM tools, it would be possible to train a **simpler, faster multi-target regression model** that mimics their behavior. Regression models also have the advantage of being inherently more interpretable.\n",
    "\n",
    "All the work described above relates to textual data, but a speaker's **voice and facial expressions** are another source for the evaluation of leadership (Antonakis & Eubanks, 2017). It would be interesting to gather then analyze the audio and/or video of those same TED(x) talks. As in the project led by Garner, this would require an initial coding phase to classify talks based on certain aspects of the speaker's speech (pitch, volume, speed, tone of voice, pauses...) or appeareance (e.g. face symmetry). Other criteria than CLTs or personality traits would first have to be identified in order to bring that work to fruition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple ways of acquiring the initial TED talks metadata were explored:\n",
    "\n",
    "* **Using an unofficial TED API**: it looked promising but was rejected because of its pricing plan and the lack of control over which metadata to extract. Besides, querying the API requires a known parameter like the name of the speaker or the YouTube ID, information that was not in our possession at the start of this project.\n",
    "* **Downloading an existing dataset**: user _rounakbanik_ from Kaggle published a dataset of about 2,500 TED talks containing both metadata and transcripts. We decided not to use it because of the relatively small number of talks and the fact that it only goes until September 2017. However, we should note the presence of a feature which does not exists anymore, `ratings`. At some point, the website users were able to rate the talks using terms such as \"inspiring\", \"fascinating\", \"jaw dropping\", etc. These votes could be integrated at a later stage by joining the Kaggle dataset to our own, and learning the ratings for records where this feature is missing.\n",
    "* **Parsing the TED RSS feed**: suggested on [StackOverflow](https://stackoverflow.com/questions/7239836/ted-talk-api-or-workaround-for-data-access), parsing the XML file of the TED talks [RSS feed](http://feeds.feedburner.com/TedtalksHD?fmt=xml) was also considered, but quickly rejected because of its short time range (one year only) and the lack of relevant metadata. \n",
    "* **Custom web scraper**: given the poor options available to us, we decided to build a custom scraper for the TED website, based on preexisting work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The companion code of a research project named \"Awe the Audience: How Emotional Trajectories Affect Audience Perception in Public Speaking\", available on [GitHub](https://github.com/ROC-HCI/TEDTalk_Analytics), served as the basis for the structure of many of our scripts.\n",
    "\n",
    "Our **web scraper**, `ted_scraper.py`, has been updated to accommodate changes done to the TED website since 2017. It goes through all possible talk IDs (61,715 at the time of the writing of this piece) and, using the `BeautifulSoup` library, parses each talk's JSON object (which is readily available in the HTML source) in order to extract the **metadata**.\n",
    "\n",
    "A second HTTP request is sent to get the talk's **transcript**, which is found at a different URL. All the data is then saved to a CSV file. The IDs from successful and failed attempts (mostly 404 or 410 errors) are saved to log files to keep track of our progress.\n",
    "\n",
    "The scraping took place from **March 8 to March 28 2020**. This long period of time can be explained by two factors.\n",
    "\n",
    "First, querying the TED website is a **slow process**. As previously stated, two HTTP requests must be done for each ID (one for the metadata, the other for the transcript). Moreover, to avoid getting timed out too often, the script waits for two seconds between each request. When we _do_ get timed out, the script waits for a random number of seconds between 1 and 60.\n",
    "\n",
    "Second, we encountered **several issues** which forced us to start over again. For example, some data would not be written correctly to the CSV file (i.e., fields being split across several lines, or some records not being written at all unless a `flush()` is performed) or some errors were not handled correctly. But more importantly, we realized only later that we would need the YouTube ID in order to supplement our dataset with the YouTube data. We noticed at the same time that the native language was also available in the JSON object. This information proved to be very valuable, because it allowed us to exclude all non-English talks (in which we were not interested).\n",
    "\n",
    "After having crawled the entirety of the talks, we noticed that a couple of IDs redirected the user to existing videos, which produced **duplicates** that had to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all the data available on the TED website, not many are of actual interest to this project, but for the sake of completeness and possible future research, we decided to gather a bit **more data than necessary**. The full list of features is as follows:\n",
    "\n",
    "* `id`: a _numerus currens_ to uniquely identify each talk in the TED database, e.g. 30200.\n",
    "* `url`\n",
    "* `main_speaker`\n",
    "* `title`\n",
    "* `full_name`: a string containing both the main speaker's name and the title of his presentation. Note that this convention is not always respected and that sometimes the `title` also contains the speaker, or the event is included as well.\n",
    "* `event`: the actual event where the talk took place, e.g. TEDxLakeComo.\n",
    "* `event_type`: there are 8 different TED talk types, the most prominent of which being TED stage talks and TEDx talks.\n",
    "* `description`: a small text describing the contents of the talk.\n",
    "* `tags`: a semi-colon-separated list of keywords related to the talk.\n",
    "* `date_recorded`\n",
    "* `date_published`\n",
    "* `duration`: the video's duration. Note that many talks are not hosted on the TED website but on YouTube, so this feature has a value of 0 for the majority of records. See also `ext_duration`.\n",
    "* `native_language`: the language spoken in the talk. When there are multiple languages, this feature takes the value of \"mul\".\n",
    "* `nb_languages`: the number of languages for which a transcript exists (this can be used as an indicator of popularity)\n",
    "* `views`: the number of views. For the same reason as the `duration`, this often has a value of 0.\n",
    "* `nb_comments`: when the comment functionality is not enabled, this gets a value of -1.\n",
    "* `nb_speakers`\n",
    "* `speakers`: a semi-colon-separated list of speakers.\n",
    "* `speakers_desc`: a semi-colon-separated list of speaker descriptions.\n",
    "* `ext_src`: the external service where videos are hosted, namely YouTube (close to 100% of talks are available on YouTube).\n",
    "* `ext_id`: the external (i.e., YouTube) ID, used at a later stage to query the YouTube API.\n",
    "* `ext_duration`: the YouTube video's duration, which can be used when `duration` is not available.\n",
    "* `transcript`: only English transcripts are scraped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon seeing that the TED website did not contain that many transcripts, and that most talks are actually hosted on YouTube, we decided to explore the YouTube data in the hope of **acquiring more transcripts**, as well as getting our hands on unique information, i.e. the number of **likes and dislikes** related to a TED talk.\n",
    "\n",
    "Our script, `youtube_api_query.py`, has a similar structure to `ted_scraper.py`. However, since YouTube provides developers with an API, we extracted that data by **querying the API** instead of scraping the website. One clear advantage of this is that data can be obtained very fast without getting timed out. However, Google imposes a daily quota of 10,000 units. Knowing that each query costs 7 units, this means that only about 1,400 records can be queried per day.\n",
    "\n",
    "The harvesting of the YouTube data started on **March 20** and ended on **April 30 2020**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for the sake of completeness, we kept more information than was actually necessary to us.\n",
    "\n",
    "* `id`: an 11-character string that uniquely identifies the YouTube video, e.g. SEDvD1IICfE.\n",
    "* `channel`: the channel where the video was uploaded.\n",
    "* `title`\n",
    "* `description`\n",
    "* `tags`: a semi-colon-separated list of keywords related to the talk.\n",
    "* `date_published`\n",
    "* `views`\n",
    "* `likes`\n",
    "* `dislikes`\n",
    "* `nb_comments`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to get the video captions through the API as well (thanks to the `captions().download()` method), the cost of doing so is quite **prohibitive** (200 units per call). Thankfully, there are alternatives to using the YouTube Data API.\n",
    "\n",
    "We initially extracted the captions found in the XML subtitle files, which can be retrieved with this URL format: [http://video.google.com/timedtext?lang=en&v=SEDvD1IICfE](http://video.google.com/timedtext?lang=en&v=SEDvD1IICfE).\n",
    "\n",
    "The drawback of this solution is that it only gives access to manually uploaded transcripts. We were later informed of the existence of the `youtube-transcript-api` library, which not only allowed us to get the **autogenerated transcripts**, but also to use **Google's translation services** to get the English version of non-English transcripts (whether these are autogenerated or not).\n",
    "\n",
    "Our script, `youtube_transcripts.py`, does precisely that. Including autogenerated and/or translated transcripts has the potential of drastically augmenting our dataset, but these come with **varying degrees of quality**. In order to keep track of the nature of each transcript (and therefore their trustworthiness), we captured key information such as whether the script was `autogenerated` (0/1) and/or `translated` (0/1), as well as the source language (2-letter ISO code).\n",
    "\n",
    "The code for the initial solution (using XML files) is still available in `youtube_api_query.py`. We kept it there in case the aforementioned library stops working one day (it is based on the YouTube web client, which is an undocumented part of the YouTube API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM personality profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The personality profiles come from IBM Watson Personality Insights, a MLaaS tool that performs psycholinguistic analyses based on text data. Among many variables, the data contains the **percentile** (i.e., a value between 0 and 1 indicating where the text's author stands with regard to the total population) for each of the **Big Five personality traits** (openness, conscientiousness, extroversion, agreeableness and neuroticism).\n",
    "\n",
    "In order to work properly, the IBM tool requires an input of **at least 100 words**. A minimum of 600 words (preferably 1,200) are needed for the service to produce statistically significant estimates.\n",
    "\n",
    "The script used to query the IBM API is `ibm_api_query.py`. Each **JSON object** returned by the service contains the full `profile`, which is simply saved as a character string to a CSV file, along with the corresponding talk `id`. Talks containing less than 100 words are logged as failures.\n",
    "\n",
    "Because IBM's free plan limits the number of API calls per month, several accounts were used to speed up the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the request of Prof. Antonakis, we looked into ways of obtaining additional information about the TED(x) speakers, namely an **estimation of their age and gender**. So as not to rely solely on one service, we adopted two complementary approaches to achieve that goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Microsoft Azure Face API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach consisted of using the Face API from Microsoft Azure, a tool that can **detect faces in images** and infer various attributes from them such as age, gender, mood, hair color, and many more. For each talk, we fed the API with the URLs to the **speaker's photo** (when it was available) as well as the **video thumbnail** from the TED website (these URLs were obtained using the `ted_scraper.py` script).\n",
    "\n",
    "`azure_api_query.py` is the script used to communicate with and save results from the Face API. When a face is detected in an image, the script simply **extracts the gender and age information**. These estimates are handled as follows:\n",
    "\n",
    "* In case of contradicting information about the gender, we assume that the photo gives a more accurate prediction than the thumbnail.\n",
    "* For the age, the script simply computes the average of both estimates.\n",
    "* If multiple faces are detected (a scenario which we think to be quite rare), we assume the first one to be the right one.\n",
    "\n",
    "The free plan allows for 20 transactions per minute, so the script sleeps for 3.5 seconds before each request to avoid getting locked out.\n",
    "\n",
    "Talks for which neither the age or gender could be retrieved were logged as failures. Otherwise, the `est_age` and `est_gender` were written to a CSV file along with the talk `id`.\n",
    "\n",
    "This approach is **limited** because the quality of the output can only be as good as the quality of the input. In many cases, the service could not detect any faces for multiple reasons:\n",
    "\n",
    "* Instead of a picture showing the actual speaker, the video thumbnail might be a generic slide provided for that particular TED(x) event.\n",
    "* Oftentimes, the speaker photo does not exists.\n",
    "* The image might be too small (the minimum detectable face size is 36 by 36 pixels).\n",
    "\n",
    "As a result, the age and gender information are **missing** in thousands of records. A way to circumvent this problem would be to get multiple snapshots from the YouTube videos and get predictions for those. However, given the total number of records, this would most likely require a paid plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian mixture models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **gender estimation**, we complemented our previous approach, based on image analysis, with a second one based on **audio analysis**.\n",
    "\n",
    "To do this, we reused the work done in the [PyGender-Voice](https://github.com/abhijeet3922/PyGender-Voice/) project. The code, written for Python 2.7, had to be adapted in order to accommodate Python 3.X. In a nutshell, this script extracts speech features known as _Mel Frequency Cepstrum Coefficients_ (MFCC) from audio files; these features can be used to identify gender.\n",
    "\n",
    "As per the author's instructions, we trained a **Gaussian mixture model** (GMM) for each gender (male/female) using Google's AudioSet (which can be downloaded [here](https://www.dropbox.com/s/sqg7az7fja6rqfw/pygender.zip?dl=0)) and saved those as .gmm files. For each talk, we downloaded the **YouTube audio** (with the help of the `youtube-dl` library) and converted it to a 16-bit WAV file using `ffmpeg` (keeping only the first 3 minutes to speed up computation). Finally, both models provided their score and the highest one determined the gender. Just like the Azure data, the `est_gender` was saved to a CSV file. When they occured, failures were primarily due to the videos being private.\n",
    "\n",
    "After checking a few select results, we are quite confident in the **quality of the predictions**. The algorithm can sometimes be thrown off, e.g. when encountering a man singing. This is no major issue, since art performances do not interest us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and merging the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collection process resulted in the creation of **6 datasets**:\n",
    "\n",
    "* TED\n",
    "* YouTube metadata\n",
    "* YouTube transcripts\n",
    "* IBM personality profiles\n",
    "* Azure ages and genders\n",
    "* GMM genders\n",
    "\n",
    "Since they are contained in separate CSV files, we first need to merge them. The TED dataset is considered to be the main one, the role of the others simply being to augment it.\n",
    "\n",
    "Before running the `load_merge()` function, one has to make sure that the relative links to the data sources (found at the top of `notebook_functions.py`) are up-to-date. Absolute links to their online version can be found in this project's README, but, because of their size, we advise to download the files first, then place them in their respective output folder (or simply clone the whole project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH TALKS: 39001\n",
      "  w/o transcript: 4258\n",
      "  w/ transcript: 34743\n",
      "    from TED: 4741\n",
      "    from YouTube: 30002\n",
      "      manually created: 105\n",
      "      autogenerated (English): 29164\n",
      "      translated (Google): 1\n",
      "      autogenerated then translated: 732\n",
      "-----\n",
      "NON-ENGLISH TALKS: 18358\n",
      "  w/o transcript: 7246\n",
      "  w/ English transcript: 11112\n",
      "    from TED: 565\n",
      "    from YouTube: 10547\n",
      "      manually created: 63\n",
      "      autogenerated (English): 239\n",
      "      translated (Google): 1037\n",
      "      autogenerated then translated: 9208\n",
      "-----\n",
      "TOTAL: 57359\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from notebook_functions import load_merge\n",
    "from notebook_functions import transcript_summary\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "df = load_merge()\n",
    "transcript_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts: merging outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close to **68%** of the talks are spoken in **English** (39,001). TED provides a human-written transcript for about 12% of them. Another 77% was extracted from YouTube.\n",
    "\n",
    "From the pool of _non-English_ talks (18,358 records), we could get an English transcript for about 60% of them. That being said, since we are only interested in TED talks that were originally spoken in English, we simply **disregard all non-English talks** during the cleaning phase.\n",
    "\n",
    "At this point, we can ask ourselves the following question: was it worth querying YouTube in order to enrich our dataset? As we can see in the figures above, merging our original TED dataset with the YouTube dataset has allowed us to get the English transcript for an additional **30,002 records**. Most of these, however, were **autogenerated** and, even if Google's speech-to-text engine is quite performant, they should be taken with a grain of salt. In practical terms, this means that less weight should be given to them when building machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning process & operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as **data types** are concerned, most of the numerical data was identified as floats. We converted these features to integers because it made more sense given their nature. We also created proper date-time objects from the timestamps.\n",
    "\n",
    "Next, we looked at **transcript quality**. We know that the TED transcripts were written by humans and therefore can be trusted. For the ones coming from YouTube, however, it's another story. From the summary statistics above, we deduce that some transcripts are probably of dubious quality and should be discarded, such as the 732 English talks that were autogenerated from a language other than English, as well as the 239 transcripts of _non-English_ talks that were autogenerated from English.\n",
    "\n",
    "We also removed transcripts containing **less than 100 characters** for several reasons:\n",
    "\n",
    "* They may contain irrelevant data like \"WEBVTT\".\n",
    "* They may represent art performances (dance, music).\n",
    "* The IBM tool requires at least 100 words to run.\n",
    "\n",
    "Most of the remaining cleaning operations were about **unifying similar fields** from both the TED and YouTube datasets. When data from the TED dataset was missing (e.g. duration = 0, no comments, no transcript, etc.), we retrieved its equivalent from the YouTube dataset (if it was available). Numeric values from both sources, such as views and comments, were **added** to get an overall picture.\n",
    "\n",
    "We then got rid of **redundant columns**, either because they did not interest us in the scope of this project, or contained duplicate information. The remaining columns were renamed and reordered.\n",
    "\n",
    "Since transcripts are the most relevant feature for this project, we **split the data** into two separate dataframes:\n",
    "\n",
    "* English talks _with_ transcript (`df`)\n",
    "* English talks _without_ transcript (`df_notranscript`)\n",
    "\n",
    "Finally, for talks having a transcript, we unpacked the relevant values from the IBM personality profile, i.e. the **Big Five percentiles**.\n",
    "\n",
    "NB: the cleaning function contains several parameters to remove specific categories of records according to the user's needs (mostly to avoid encountering null values during regression):\n",
    "\n",
    "* `remove_autogenerated`: remove records with an autogenerated YouTube transcript (which could potentially improve the models, even though this discards a large portion of transcripts).\n",
    "* `remove_empty_popularity`: remove records that do not have a popularity score (about 100 talks; see section below).\n",
    "* `remove_empty_big5`: remove records that do not have a personality profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional feature: YouTube popularity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the goal of the project is to check whether the use of CLTs in a talk is **correlated with follower reaction**. The problem is that the data presents us with several metrics that could be used for that purpose : views, likes and dislikes, comments, the number of languages the talk was translated to... Therefore, we wanted to **combine** some of them in order to get a single metric.\n",
    "\n",
    "The formula we settled on is the following:\n",
    "\n",
    "$$\\frac{\\ln({\\sqrt{\\frac{likes+1}{dislikes+1}}\\times views})}{1+\\frac{\\ln{days}}{\\sqrt{\\ln{days}}}}$$\n",
    "\n",
    "The idea behind this formula is to use the **like-to-dislike ratio** (to both of which 1 is added in order to prevent null results) as a way to tell how much a view is worth. A perfect balance of likes and dislikes translates to a ratio of 1, which does not change the value of each view.\n",
    "\n",
    "Since this ratio can potentially get disproportionately big, it is squared. The **natural logarithm** is then applied to the whole dividend in order to get a reasonable order of magnitude.\n",
    "\n",
    "Since views and (dis)likes are a function of time, we control for the **time elapsed** (in days) between the publication of the video on YouTube and April 30 2020, which is when the querying of the YouTube API ended (ideally, a timestamp should have been recorded at the time of query in order to get a more accurate value). Because the daily number of views on a video naturally decreases over time after a a while (usually), we designed the formula's divisor in such a way that it does not increase linearly.\n",
    "\n",
    "Finally, the values are normalized using **min-max scaling** in order to get a more interpretable scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of our scripts require data from the original TED dataset as **input** (such as YouTube IDs or transcripts). Therefore, the `clean` function below also includes an `export` parameter to specify which data should be exported by adding arguments to a list of strings:\n",
    "\n",
    "* \"yt_ids\": list of YouTube IDs, used in conjunction with the YouTube Data API, the `youtube-dl` library and the `youtube-transcript-api` library.\n",
    "* \"ted_yt_ids\": same as above, but with TED IDs as well.\n",
    "* \"transcripts\": transcripts and their respective TED IDs, which can be used for the IBM tool (`remove_empty_big5` should then be set to \"False\").\n",
    "* \"uncleaned\": in case the entire raw data (i.e., before cleaning) is needed.\n",
    "* \"cleaned\": the final version of the dataset, for dissemination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH TALKS (post-cleaning): 38282\n",
      "  w/ transcript: 34357\n",
      "  w/o transcript: 3925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_YT</th>\n",
       "      <th>url_TED</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>talk_full_name</th>\n",
       "      <th>event</th>\n",
       "      <th>event_type</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>date_published_TED</th>\n",
       "      <th>date_published_YT</th>\n",
       "      <th>duration</th>\n",
       "      <th>language</th>\n",
       "      <th>transcript</th>\n",
       "      <th>autogenerated</th>\n",
       "      <th>combined_views_TED_YT</th>\n",
       "      <th>combined_comments_TED_YT</th>\n",
       "      <th>likes_YT</th>\n",
       "      <th>dislikes_YT</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>predicted_gender_GMM</th>\n",
       "      <th>predicted_gender_AZURE</th>\n",
       "      <th>predicted_age_AZURE</th>\n",
       "      <th>big5_O</th>\n",
       "      <th>big5_C</th>\n",
       "      <th>big5_E</th>\n",
       "      <th>big5_A</th>\n",
       "      <th>big5_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rDiGYuQicpA</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_averting_the...</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>TED Stage Talk</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>alternative energy;cars;climate change;culture...</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>977</td>\n",
       "      <td>en</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>3705229</td>\n",
       "      <td>580</td>\n",
       "      <td>815</td>\n",
       "      <td>262</td>\n",
       "      <td>0.578499</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>52</td>\n",
       "      <td>0.989001</td>\n",
       "      <td>0.728937</td>\n",
       "      <td>0.457696</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.127530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FwFkb1x7FJQ</td>\n",
       "      <td>https://www.ted.com/talks/amy_smith_simple_des...</td>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Amy Smith: Simple designs to save a life</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>TED Stage Talk</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>MacArthur grant;alternative energy;design;engi...</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-08-15</td>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>906</td>\n",
       "      <td>en</td>\n",
       "      <td>In terms of invention, I'd like to tell you th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1747320</td>\n",
       "      <td>120</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>0.475780</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>48</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.694569</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>0.134628</td>\n",
       "      <td>0.102085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A6GLw12jywo</td>\n",
       "      <td>https://www.ted.com/talks/ashraf_ghani_how_to_...</td>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani: How to rebuild a broken state</td>\n",
       "      <td>TEDGlobal 2005</td>\n",
       "      <td>TED Stage Talk</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>business;corruption;culture;economics;entrepre...</td>\n",
       "      <td>2005-07-12</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>1125</td>\n",
       "      <td>en</td>\n",
       "      <td>A public, Dewey long ago observed, is constitu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1096933</td>\n",
       "      <td>319</td>\n",
       "      <td>1235</td>\n",
       "      <td>110</td>\n",
       "      <td>0.568619</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>52</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.665497</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.048604</td>\n",
       "      <td>0.141556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        id_YT                                            url_TED  \\\n",
       "0   1  rDiGYuQicpA  https://www.ted.com/talks/al_gore_averting_the...   \n",
       "1   2  FwFkb1x7FJQ  https://www.ted.com/talks/amy_smith_simple_des...   \n",
       "2   3  A6GLw12jywo  https://www.ted.com/talks/ashraf_ghani_how_to_...   \n",
       "\n",
       "   main_speaker                          title  \\\n",
       "0       Al Gore    Averting the climate crisis   \n",
       "1     Amy Smith  Simple designs to save a life   \n",
       "2  Ashraf Ghani  How to rebuild a broken state   \n",
       "\n",
       "                                talk_full_name           event  \\\n",
       "0         Al Gore: Averting the climate crisis         TED2006   \n",
       "1     Amy Smith: Simple designs to save a life         TED2006   \n",
       "2  Ashraf Ghani: How to rebuild a broken state  TEDGlobal 2005   \n",
       "\n",
       "       event_type                                        description  \\\n",
       "0  TED Stage Talk  With the same humor and humanity he exuded in ...   \n",
       "1  TED Stage Talk  Fumes from indoor cooking fires kill more than...   \n",
       "2  TED Stage Talk  Ashraf Ghani's passionate and powerful 10-minu...   \n",
       "\n",
       "                                                tags date_recorded  \\\n",
       "0  alternative energy;cars;climate change;culture...    2006-02-25   \n",
       "1  MacArthur grant;alternative energy;design;engi...    2006-02-24   \n",
       "2  business;corruption;culture;economics;entrepre...    2005-07-12   \n",
       "\n",
       "  date_published_TED date_published_YT duration language  \\\n",
       "0         2006-06-27        2007-01-16      977       en   \n",
       "1         2006-08-15        2007-01-16      906       en   \n",
       "2         2006-10-18        2007-01-12     1125       en   \n",
       "\n",
       "                                          transcript  autogenerated  \\\n",
       "0  Thank you so much, Chris. And it's truly a gre...              0   \n",
       "1  In terms of invention, I'd like to tell you th...              0   \n",
       "2  A public, Dewey long ago observed, is constitu...              0   \n",
       "\n",
       "   combined_views_TED_YT  combined_comments_TED_YT  likes_YT  dislikes_YT  \\\n",
       "0                3705229                       580       815          262   \n",
       "1                1747320                       120       161            7   \n",
       "2                1096933                       319      1235          110   \n",
       "\n",
       "   popularity_score predicted_gender_GMM predicted_gender_AZURE  \\\n",
       "0          0.578499                 male                   male   \n",
       "1          0.475780               female                 female   \n",
       "2          0.568619                 male                   male   \n",
       "\n",
       "   predicted_age_AZURE    big5_O    big5_C    big5_E    big5_A    big5_N  \n",
       "0                   52  0.989001  0.728937  0.457696  0.298817  0.127530  \n",
       "1                   48  0.981490  0.694569  0.229315  0.134628  0.102085  \n",
       "2                   52  0.997457  0.665497  0.386800  0.048604  0.141556  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook_functions import clean\n",
    "df, df_notranscript = clean(df,\n",
    "                            remove_autogenerated=False,\n",
    "                            remove_empty_popularity=True,\n",
    "                            remove_empty_big5=True,\n",
    "                            export=[])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization (for later use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both fitting and transforming the whole data using TF-IDF take a _very_ long time (an entire day). For testing, it is preferable to use **Doc2Vec** (which seems to provide better accuracy anyway)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34357x145615 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12435192 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "punctuation = string.punctuation + \"â€”\"\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "def tokenizer(transcript):\n",
    "    tokens = nlp(transcript)\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in punctuation and word not in stopwords]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "sample = df.sample(frac=1, random_state=RSEED)  # lower fraction to speed up computation\n",
    "fitted = True\n",
    "\n",
    "if fitted:\n",
    "    vectorizer = pickle.load(open(\"tfidf_vec_full.pickle\", \"rb\"))\n",
    "    X_tfidf = vectorizer.transform(sample[\"transcript\"])\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1,1))\n",
    "    X_tfidf = vectorizer.fit_transform(sample[\"transcript\"])\n",
    "    pickle.dump(vectorizer, open(\"vectorizer.pickle\", \"wb\"))\n",
    "\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "sample = df.sample(frac=1, random_state=RSEED)  # lower fraction to speed up computation\n",
    "model_exists = False\n",
    "fname = \"model.d2v\"\n",
    "\n",
    "if model_exists:\n",
    "    model = Doc2Vec.load(fname)\n",
    "else:\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sample[\"transcript\"])]\n",
    "    model = Doc2Vec(documents, vector_size=10, window=1, min_count=1, workers=8, seed=RSEED)\n",
    "    model.save(fname)\n",
    "\n",
    "def get_vectors(model, documents):\n",
    "    return [model.infer_vector(doc.words) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (for later use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, the **random forest** provides a slightly better accuracy than k-nearest neighbors (1 to 5%). However, the latter has a near-instant training time, which is useful for testing (adjustments in the vectorization parameters seem to lead to the same trends in accuracy changes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validation and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "mode = (\"d2v\", \"popularity\")\n",
    "\n",
    "if mode[0] == \"d2v\":\n",
    "    tagged_docs = [TaggedDocument(words=str(doc).split(), tags=[str(i)]) for i, doc in list(enumerate(df[\"transcript\"]))]\n",
    "    X = np.array(get_vectors(model, tagged_docs))\n",
    "else:\n",
    "    X = X_tfidf\n",
    "\n",
    "if mode[1] == \"popularity\":\n",
    "    y = df[\"popularity_score\"]\n",
    "else:\n",
    "    y = df[\"big5_O\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1-train_ratio), random_state=RSEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=(test_ratio/(test_ratio + val_ratio)), random_state=RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameter_tuning = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "\tn_neighbors = 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.440608379770088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "if hyperparameter_tuning:\n",
    "    gs_knn = GridSearchCV(KNeighborsRegressor(n_jobs=-1),\n",
    "                      param_grid={\n",
    "                          \"n_neighbors\": range(10,35)\n",
    "                      })\n",
    "    gs_knn.fit(X_val, y_val)\n",
    "\n",
    "    knn_scores = gs_knn.cv_results_\n",
    "    neighbors = gs_knn.best_params_[\"n_neighbors\"]\n",
    "else:\n",
    "    neighbors = 15\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(\"\\tn_neighbors =\", neighbors)\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors=neighbors, n_jobs=-1)\n",
    "KNN.fit(X_train, y_train)\n",
    "KNN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "\tn_estimators = 5000\n",
      "\tmax_depth = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4533905087626361"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if hyperparameter_tuning:\n",
    "    gs_rf = GridSearchCV(RandomForestRegressor(n_jobs=-1, random_state=RSEED),\n",
    "                      param_grid={\n",
    "                          \"n_estimators\": [10, 100, 500, 1000, 5000],\n",
    "                          \"max_depth\": [10, 100, 500, 1000, 5000],\n",
    "                      })\n",
    "    gs_rf.fit(X_val, y_val)\n",
    "\n",
    "    rf_scores = gs_rf.cv_results_\n",
    "    estimators = gs_rf.best_params_[\"n_estimators\"]\n",
    "    depth = gs_rf.best_params_[\"max_depth\"]\n",
    "else:\n",
    "    estimators = 5000\n",
    "    depth = 10\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(\"\\tn_estimators =\", estimators)\n",
    "print(\"\\tmax_depth =\", depth)\n",
    "\n",
    "RF = RandomForestRegressor(n_estimators=estimators, max_depth=depth, n_jobs=-1, random_state=RSEED)\n",
    "RF.fit(X_train, y_train)\n",
    "RF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antonakis, J. (2006). Leadership: What is it and how it is implicated in strategic change? International Journal of Management Cases, 8(4), 17 p.\n",
    "\n",
    "Antonakis, J., Bastardoz, N., Jacquart, P., & Shamir, B. (2016). Charisma: An ill-defined and ill-measured gift. Annual Review of Organizational Psychology and Organizational Behavior, 3, 293-319.\n",
    "\n",
    "Antonakis, J., & Eubanks, D.L. (2017). Looking leadership in the face. Current Directions in Psychological Science, 26(3), 270-275.\n",
    "\n",
    "Antonakis, J., Fenley, M., & Liechti, S. (2011). Can charisma be taught? Tests of two interventions. Academy of Management Learning & Education, 10(3), 374-396.\n",
    "\n",
    "Antonakis, J., Fenley, M., & Liechti, S. (2012). Learning charisma: Transform yourself into the person others want to follow. Harvard Business Review, 90(6), 127-130.\n",
    "\n",
    "Garner, P.N., Antonakis, J., Bornet, O., Loupi, D., & Rohner, D. (2018). Deep learning of charisma. Manuscript in preparation.\n",
    "\n",
    "Jacquart, P., Antonakis, J. (2015). When does charisma matter for top-level leaders? Effect of attributional ambiguity. Academy of Management Journal, 58(4), 1051-1074.\n",
    "\n",
    "Simonton, D.K. (2006). Presidential IQ, openness, intellectual brilliance, and leadership: Estimates and correlations for 42 U.S. chief executives. Political Psychology, 27(4), 511-526."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
